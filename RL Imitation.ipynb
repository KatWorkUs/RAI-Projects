{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ca09c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python311\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.13.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame, sys, os, time\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe64e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCREEN_W, SCREEN_H = 640, 480\n",
    "EE_R = 8\n",
    "BLOCK_R = 14\n",
    "TARGET_R = 18\n",
    "DEMO_PATH = \"demos.npy\"\n",
    "MODEL_PATH = \"bc_imitation.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PickPlace:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.ee = np.array([SCREEN_W/2, SCREEN_H/2], dtype=np.float32)\n",
    "        self.block = np.array([np.random.uniform(80,SCREEN_W-80), np.random.uniform(80,SCREEN_H-120)], dtype=np.float32)\n",
    "        self.has_block = False\n",
    "        self.target = np.array([SCREEN_W/2, 60], dtype=np.float32)\n",
    "        return self.get_state()\n",
    "    def get_state(self):\n",
    "        st = [self.ee[0]/SCREEN_W, self.ee[1]/SCREEN_H,\n",
    "              self.block[0]/SCREEN_W, self.block[1]/SCREEN_H,\n",
    "              self.target[0]/SCREEN_W, self.target[1]/SCREEN_H,\n",
    "              float(self.has_block)]\n",
    "        return np.array(st, dtype=np.float32)\n",
    "    def step(self, action):\n",
    "        self.ee += action\n",
    "        self.ee = np.clip(self.ee, [EE_R, EE_R], [SCREEN_W-EE_R, SCREEN_H-EE_R])\n",
    "        # pick if close\n",
    "        if not self.has_block and np.linalg.norm(self.ee - self.block) < (EE_R + BLOCK_R + 4):\n",
    "            self.has_block = True\n",
    "        # carry block\n",
    "        if self.has_block:\n",
    "            self.block = self.ee.copy()\n",
    "        done = False\n",
    "        success = False\n",
    "        if self.has_block and np.linalg.norm(self.block - self.target) < (TARGET_R):\n",
    "            done = True\n",
    "            success = True\n",
    "        return self.get_state(), done, success\n",
    "\n",
    "# ---------- BC model ----------\n",
    "class BCNet(nn.Module):\n",
    "    def __init__(self, in_dim=7, out_dim=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim,128), nn.ReLU(),\n",
    "            nn.Linear(128,128), nn.ReLU(),\n",
    "            nn.Linear(128,out_dim)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "# ---------- utilities ----------\n",
    "def load_demos(path=DEMO_PATH):\n",
    "    if os.path.exists(path):\n",
    "        return np.load(path, allow_pickle=True)\n",
    "    return np.zeros((0,))\n",
    "\n",
    "def save_demos(data, path=DEMO_PATH):\n",
    "    np.save(path, data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e00ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2422 demo steps.\n",
      "Recording: True\n",
      "Saved demos: 2600\n",
      "Reset env\n",
      "Saved demos: 2800\n",
      "Reset env\n",
      "Saved demos: 3000\n",
      "Reset env\n",
      "Saved demos: 3200\n",
      "Reset env\n",
      "Saved demos: 3400\n",
      "Reset env\n",
      "Saved demos: 3600\n",
      "Reset env\n",
      "Saved demos: 3800\n",
      "Autonomous: True\n",
      "Recording: False\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_W, SCREEN_H))\n",
    "    pygame.display.set_caption(\"Imitation (BC) - press d to record, t train, p play, s save, l load\")\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    env = PickPlace()\n",
    "    state = env.reset()\n",
    "    demos = []\n",
    "    demos_arr = load_demos()\n",
    "    if demos_arr.size:\n",
    "        demos = list(demos_arr.tolist())\n",
    "        print(f\"Loaded {len(demos)} demo steps.\")\n",
    "    model = BCNet().to(DEVICE)\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    recording = False\n",
    "    mode = \"idle\"  # 'autonomous'\n",
    "    run_autonomous = False\n",
    "\n",
    "    while True:\n",
    "        for e in pygame.event.get():\n",
    "            if e.type == pygame.QUIT:\n",
    "                save_demos(np.array(demos, dtype=object), DEMO_PATH)\n",
    "                pygame.quit(); return\n",
    "            elif e.type == pygame.KEYDOWN:\n",
    "                if e.key==pygame.K_d:\n",
    "                    recording = not recording\n",
    "                    print(\"Recording:\", recording)\n",
    "                elif e.key==pygame.K_t:\n",
    "                    # train BC quickly\n",
    "                    if len(demos) < 20:\n",
    "                        print(\"Need more demo data (>=20 steps). Current:\", len(demos))\n",
    "                    else:\n",
    "                        print(\"Training BC on\", len(demos), \"samples\")\n",
    "                        data = np.array(demos)\n",
    "                        X = np.stack(data[:,0]).astype(np.float32)\n",
    "                        Y = np.stack(data[:,1]).astype(np.float32)\n",
    "                        X_t = torch.tensor(X, device=DEVICE)\n",
    "                        Y_t = torch.tensor(Y, device=DEVICE)\n",
    "                        for ep in range(60):\n",
    "                            idx = np.random.permutation(len(X))\n",
    "                            batch = 64\n",
    "                            losses=[]\n",
    "                            for i in range(0,len(X),batch):\n",
    "                                bidx = idx[i:i+batch]\n",
    "                                xb = X_t[bidx]; yb = Y_t[bidx]\n",
    "                                pred = model(xb)\n",
    "                                loss = loss_fn(pred, yb)\n",
    "                                opt.zero_grad(); loss.backward(); opt.step()\n",
    "                                losses.append(loss.item())\n",
    "                            if ep%10==0:\n",
    "                                print(f\"Epoch {ep} loss {np.mean(losses):.4f}\")\n",
    "                        print(\"Training done.\")\n",
    "                elif e.key==pygame.K_p:\n",
    "                    run_autonomous = not run_autonomous\n",
    "                    print(\"Autonomous:\", run_autonomous)\n",
    "                elif e.key==pygame.K_r:\n",
    "                    state = env.reset()\n",
    "                    print(\"Reset env\")\n",
    "                elif e.key==pygame.K_s:\n",
    "                    torch.save(model.state_dict(), MODEL_PATH)\n",
    "                    print(\"Saved model\")\n",
    "                elif e.key==pygame.K_l:\n",
    "                    if os.path.exists(MODEL_PATH):\n",
    "                        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "                        print(\"Loaded model\")\n",
    "                    else:\n",
    "                        print(\"No model file found\")\n",
    "            elif e.type == pygame.MOUSEMOTION:\n",
    "                if recording:\n",
    "                    # if recording, interpret mouse movement as action\n",
    "                    mx,my = e.pos\n",
    "                    # we'll compute action as delta from ee to mouse but clipped\n",
    "                    pass\n",
    "\n",
    "        # get input / control\n",
    "        mx,my = pygame.mouse.get_pos()\n",
    "        mouse_buttons = pygame.mouse.get_pressed()\n",
    "        # action = small delta towards mouse (teleop)\n",
    "        delta = np.array([mx - env.ee[0], my - env.ee[1]], dtype=np.float32)\n",
    "        # normalize step size\n",
    "        max_step = 8.0\n",
    "        dist = np.linalg.norm(delta)\n",
    "        if dist > 1e-3:\n",
    "            action = (delta / dist) * min(max_step, dist)\n",
    "        else:\n",
    "            action = np.array([0.0, 0.0], dtype=np.float32)\n",
    "\n",
    "        # if autonomous: let model predict\n",
    "        if run_autonomous:\n",
    "            with torch.no_grad():\n",
    "                s_t = torch.tensor(env.get_state(), dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "                a_t = model(s_t).squeeze(0).cpu().numpy()\n",
    "            action = a_t\n",
    "\n",
    "        # step env\n",
    "        state_before = env.get_state()\n",
    "        state_after, done, success = env.step(action)\n",
    "        # recording: store (state, action)\n",
    "        if recording:\n",
    "            demos.append((state_before, action.tolist()))\n",
    "            if len(demos) % 200 == 0:\n",
    "                save_demos(np.array(demos, dtype=object), DEMO_PATH)\n",
    "                print(\"Saved demos:\", len(demos))\n",
    "\n",
    "        # render\n",
    "        screen.fill((25,25,30))\n",
    "        # target zone\n",
    "        pygame.draw.circle(screen, (60,180,70), (int(env.target[0]), int(env.target[1])), TARGET_R)\n",
    "        # block\n",
    "        col = (180,80,60) if not env.has_block else (200,180,60)\n",
    "        pygame.draw.circle(screen, col, (int(env.block[0]), int(env.block[1])), BLOCK_R)\n",
    "        # end effector\n",
    "        pygame.draw.circle(screen, (200,200,200), (int(env.ee[0]), int(env.ee[1])), EE_R)\n",
    "        # overlay\n",
    "        font = pygame.font.SysFont(\"Arial\", 16)\n",
    "        txt = font.render(f\"Record(d):{recording}  Demos:{len(demos)}  Auton(p):{run_autonomous}\", True, (240,240,240))\n",
    "        screen.blit(txt, (8,8))\n",
    "        if done:\n",
    "            txt2 = font.render(\"SUCCESS! Press r to reset.\", True, (255,220,60))\n",
    "            screen.blit(txt2, (8,35))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        clock.tick(60)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a9514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
